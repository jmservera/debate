{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 01 - Term in office downloader\r\n",
        "\r\n",
        "This first notebook is built to download all the publication page links on the https://www.congreso.es page.\r\n",
        "\r\n",
        "The process does not get the pages with the actual content, just the links to the pages with the content. This first step gets the json files that point to the pages from the search engine of the site. We will need to download the HTML pages in a following step.\r\n",
        "\r\n",
        "It will generate many files. A csv file with all the terms in the `./data` folder and a file for each tearm in the `./data/terms` folder, along with all downloaded json files."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCTIONS block\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def get_df_from_congress_json(list)->pd.DataFrame:\n",
        "    \"\"\"\n",
        "    get_df_from_pubmed_json(list) takes a list of json objects from the congress\n",
        "    and returns a pandas dataframe with the list of documents and the link to\n",
        "    the file in the `url` field.\n",
        "    \"\"\"\n",
        "    temp = []\n",
        "    page_base = 'https://www.congreso.es/busqueda-de-publicaciones?p_p_id=publicaciones&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_publicaciones_mode=mostrarTextoIntegro&_publicaciones_legislatura={}&_publicaciones_texto=&_publicaciones_id_texto={}'\n",
        "\n",
        "    for s in list:\n",
        "        if(s.startswith('documento')):\n",
        "            temp.append(list[s])\n",
        "\n",
        "    page_no = list['paginaActual']\n",
        "    #doc_len = list['publicaciones_encontradas']\n",
        "    term = list['legislatura']\n",
        "\n",
        "    print(page_no, end='')\n",
        "\n",
        "    df = pd.DataFrame(temp)\n",
        "\n",
        "    df['url'] = df.apply(lambda x: page_base.format(term, (f'{x[\"cve\"]}') if 'cve' in x else (f'{x[\"texto_integro\"][x[\"texto_integro\"].rfind(\"+\")+1:]}') ),axis=1)\n",
        "    df['term']=term\n",
        "\n",
        "    return df\n",
        "\n",
        "def get_term_json(term:str, page:int):\n",
        "  import json\n",
        "  import urllib3\n",
        "  import os\n",
        "  import io\n",
        "\n",
        "  pagequery = \"https://www.congreso.es/publicaciones-organo?p_p_id=publicaciones&p_p_lifecycle=2&p_p_state=normal&p_p_mode=view&p_p_resource_id=filtrarListado&p_p_cacheability=cacheLevelPage&_publicaciones_seccion=Congreso&_publicaciones_descOrg=Pleno-y-Diputacion-Permanente&_publicaciones_publicacion=D\"\n",
        "  http = urllib3.PoolManager()\n",
        "  headers = { 'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n",
        "              'accept':'application/json, text/javascript, */*; q=0.01'\n",
        "              }\n",
        "\n",
        "  pageform = { \"_publicaciones_legislatura\":term,\n",
        "            \"_publicaciones_comision\":'',\n",
        "            \"_publicaciones_seccion\":'',\n",
        "            \"_publicaciones_fromOrganos\":1,\n",
        "            \"_publicaciones_paginaActual\":page\n",
        "            }\n",
        "\n",
        "  r = http.request_encode_body('POST',pagequery,headers=headers,fields=pageform,encode_multipart=False)\n",
        "  data=r.data.decode('utf-8')\n",
        "  try:\n",
        "    os.makedirs('data/terms',exist_ok=True)\n",
        "    with io.open(file=f\"data/terms/term_{term}_{page}.json\",mode='w') as file:\n",
        "      file.write(data)\n",
        "  except Exception as e:\n",
        "    print(f\"could not write file data/terms/term_{term}_{page}.json: {e}\")\n",
        "\n",
        "  return json.loads(data)\n",
        "\n",
        "def get_all_pages_for_a_term(term:str)->pd.DataFrame:\n",
        "    \"\"\"\n",
        "    get_all_pages_for_a_term(term:int)->pd.DataFrame takes a term (legislature)\n",
        "    and returns a dataframe with all the documents in that term.\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import os\n",
        "    \n",
        "    term_ds = None\n",
        "    nextPage = 1\n",
        "    while nextPage:\n",
        "      list = get_term_json(term, nextPage)\n",
        "      ds = get_df_from_congress_json(list)\n",
        "      if term_ds is None:\n",
        "        term_ds = ds\n",
        "      else:\n",
        "        term_ds = pd.concat([term_ds,ds])\n",
        "      lastDoc=int(list['paginacion']['docs_fin'])\n",
        "      totalDocs=int(list['publicaciones_encontradas'])\n",
        "      if(lastDoc<totalDocs):\n",
        "        nextPage+=1\n",
        "        print('.',end=\"\")\n",
        "      else:\n",
        "        nextPage=0\n",
        "    try:\n",
        "      os.makedirs('data/terms',exist_ok=True)\n",
        "      term_ds.to_csv(f\"data/terms/term_{term}.csv\",index=False)\n",
        "    except Exception as e:\n",
        "      print(f\"could not write file data/terms/term_{term}.csv: {e}\")\n",
        "    return term_ds\n",
        "\n",
        "def get_all_terms(max:int=14)->pd.DataFrame:\n",
        "    \"\"\"\n",
        "    get_all_terms(max:int=14)->pd.DataFrame takes a maximum term and returns all\n",
        "    the documents in all the terms (from the 5th that is the one that starts\n",
        "    having raw text data).\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    full_ds = None\n",
        "    for i in range(5,max+1):\n",
        "      print(f\"Getting term {i}...\",end=\"\")\n",
        "      ds = get_all_pages_for_a_term(i)\n",
        "      if full_ds is None:\n",
        "        full_ds = ds\n",
        "      else:\n",
        "        full_ds = pd.concat([full_ds,ds])\n",
        "      print(f\"Done. {len(full_ds)} documents.\")\n",
        "    return full_ds\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 101,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "##### Constants\n",
        "\n",
        "max_term=14"
      ],
      "outputs": [],
      "execution_count": 102,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "full_ds = get_all_terms(max_term)\n",
        "\n",
        "os.makedirs('data', exist_ok=True)\n",
        "full_ds.to_csv(f\"data/full_term_up_to_{max_term}.csv\", index=False)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Getting term 5...1.2.3.4.5.6.7.8.9.10Done. 197 documents.\nGetting term 6...1.2.3.4.5.6.7.8.9.10.11.12.13.14.15Done. 483 documents.\nGetting term 7...1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16Done. 793 documents.\nGetting term 8...1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16Done. 1108 documents.\nGetting term 9...1.2.3.4.5.6.7.8.9.10.11.12.13.14.15Done. 1390 documents.\nGetting term 10...1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16Done. 1705 documents.\nGetting term 11...1Done. 1720 documents.\nGetting term 12...1.2.3.4.5.6.7.8.9.10Done. 1905 documents.\nGetting term 13...1Done. 1920 documents.\nGetting term 14...1.2.3.4.5.6.7.8.9.10.11.12Done. 2141 documents.\n"
        }
      ],
      "execution_count": 103,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "77df4a96c0be8bd891423502f384941e461f81b0e784fdbc8bb136153927d3d2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}